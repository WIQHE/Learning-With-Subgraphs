{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding Window Subgraph Extraction for Graph Classification\n",
    "\n",
    "This notebook demonstrates the sliding window approach for subgraph extraction and weakly supervised learning on graphs using Graph Attention Networks (GAT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import torch\n",
    "import torch_geometric.datasets as datasets\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Import custom modules\n",
    "from utils import create_sliding_window_subgraphs, evaluate_with_attention\n",
    "from models import GAT, train_model, test_model\n",
    "from datasets import SubgraphDataset, create_dataset_splits\n",
    "from visualization import plot_confusion_matrix, plot_training_curves, evaluate_and_visualize_top_k\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MSRC_21 dataset\n",
    "DATASET_PATH = 'dataset'\n",
    "dataset = datasets.TUDataset(root=DATASET_PATH, name=\"MSRC_21\")\n",
    "\n",
    "print(f\"Dataset: {dataset}\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "print(f\"Number of node features: {dataset.num_node_features}\")\n",
    "\n",
    "# Calculate dataset statistics\n",
    "labels = [data.y.item() for data in dataset]\n",
    "total_nodes = sum(data.num_nodes for data in dataset)\n",
    "total_edges = sum(data.num_edges for data in dataset)\n",
    "avg_nodes = total_nodes / len(dataset)\n",
    "avg_edges = total_edges / len(dataset)\n",
    "\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"Unique labels: {set(labels)}\")\n",
    "print(f\"Average nodes per graph: {avg_nodes:.2f}\")\n",
    "print(f\"Average edges per graph: {avg_edges:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Graph Classification (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create standard train/test splits for baseline comparison\n",
    "train_dataset, test_dataset = create_dataset_splits(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for full graphs\n",
    "train_loader_full = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader_full = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Training graphs: {len(train_dataset)}\")\n",
    "print(f\"Testing graphs: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model on full graphs\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "# Initialize baseline GAT model\n",
    "baseline_model = GAT(\n",
    "    num_features=dataset.num_node_features,\n",
    "    num_classes=dataset.num_classes,\n",
    "    hidden_channels=64,\n",
    "    heads=8,\n",
    "    dropout=0.6\n",
    ").to(device)\n",
    "\n",
    "baseline_optimizer = torch.optim.Adam(baseline_model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "# Training loop for baseline\n",
    "print(\"Training baseline model on full graphs...\")\n",
    "num_epochs = 50\n",
    "baseline_train_acc = []\n",
    "baseline_test_acc = []\n",
    "baseline_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    avg_loss, train_acc = train_model(baseline_model, train_loader_full, baseline_optimizer, device)\n",
    "    \n",
    "    # Test\n",
    "    test_acc, _, _ = test_model(baseline_model, test_loader_full, device)\n",
    "    \n",
    "    baseline_train_acc.append(train_acc)\n",
    "    baseline_test_acc.append(test_acc)\n",
    "    baseline_losses.append(avg_loss)\n",
    "    \n",
    "    if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "print(f\"\\nBaseline Test Accuracy: {baseline_test_acc[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window Subgraph Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window parameters\n",
    "window_params = {\n",
    "    'window_size': 62,\n",
    "    'step_size': 5\n",
    "}\n",
    "\n",
    "print(f\"Sliding window parameters: {window_params}\")\n",
    "\n",
    "# Create subgraph datasets using sliding window approach\n",
    "train_subgraph_dataset = SubgraphDataset(train_dataset, create_sliding_window_subgraphs, **window_params)\n",
    "test_subgraph_dataset = SubgraphDataset(test_dataset, create_sliding_window_subgraphs, **window_params)\n",
    "\n",
    "print(f\"Training subgraphs: {len(train_subgraph_dataset.data_list)}\")\n",
    "print(f\"Testing subgraphs: {len(test_subgraph_dataset.data_list)}\")\n",
    "\n",
    "# Create data loaders for subgraphs\n",
    "train_loader_sub = DataLoader(train_subgraph_dataset.data_list, batch_size=32, shuffle=True)\n",
    "test_loader_sub = DataLoader(test_subgraph_dataset.data_list, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader_sub)}\")\n",
    "print(f\"Testing batches: {len(test_loader_sub)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subgraph Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize subgraph model\n",
    "subgraph_model = GAT(\n",
    "    num_features=dataset.num_node_features,\n",
    "    num_classes=dataset.num_classes,\n",
    "    hidden_channels=64,\n",
    "    heads=8,\n",
    "    dropout=0.6\n",
    ").to(device)\n",
    "\n",
    "subgraph_optimizer = torch.optim.Adam(subgraph_model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Training subgraph model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for subgraph model\n",
    "num_epochs_sub = 50\n",
    "subgraph_losses = []\n",
    "subgraph_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs_sub):\n",
    "    avg_loss, accuracy = train_model(subgraph_model, train_loader_sub, subgraph_optimizer, device, criterion)\n",
    "    subgraph_losses.append(avg_loss)\n",
    "    subgraph_accuracies.append(accuracy)\n",
    "    \n",
    "    if epoch % 10 == 0 or epoch == num_epochs_sub - 1:\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs_sub}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "print(\"Subgraph model training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation with Attention-based Top-K Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using attention-based top-k subgraph selection\n",
    "print(\"Evaluating with attention-based top-k subgraph selection...\")\n",
    "\n",
    "accuracy, predictions, true_labels = evaluate_with_attention(\n",
    "    model=subgraph_model,\n",
    "    dataset=test_dataset,\n",
    "    subgraph_func=create_sliding_window_subgraphs,\n",
    "    k=3,\n",
    "    device=device,\n",
    "    **window_params\n",
    ")\n",
    "\n",
    "print(f'Subgraph-based Test Accuracy (Top-K): {accuracy:.4f}')\n",
    "print(f'Baseline Test Accuracy (Full Graph): {baseline_test_acc[-1]:.4f}')\n",
    "print(f'Improvement: {accuracy - baseline_test_acc[-1]:.4f}')\n",
    "\n",
    "# Generate class names\n",
    "class_names = [f'Class {i}' for i in range(dataset.num_classes)]\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nSubgraph-based Classification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Comparison and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for subgraph-based approach\n",
    "plot_confusion_matrix(true_labels, predictions, class_names, \n",
    "                     title=\"Sliding Window Subgraph Classification Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare training curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Baseline accuracy\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(1, len(baseline_train_acc) + 1), baseline_train_acc, 'b-', label='Train Accuracy')\n",
    "plt.plot(range(1, len(baseline_test_acc) + 1), baseline_test_acc, 'r-', label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Baseline (Full Graph) Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Subgraph training accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(1, len(subgraph_accuracies) + 1), subgraph_accuracies, 'g-', label='Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Subgraph Training Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss comparison\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(range(1, len(baseline_losses) + 1), baseline_losses, 'b-', label='Baseline Loss')\n",
    "plt.plot(range(1, len(subgraph_losses) + 1), subgraph_losses, 'g-', label='Subgraph Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Top-K Subgraph Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention-based subgraph selection for a sample graph\n",
    "print(\"Visualizing top-k subgraph selection...\")\n",
    "\n",
    "evaluate_and_visualize_top_k(\n",
    "    model=subgraph_model,\n",
    "    dataset=test_dataset,\n",
    "    subgraph_func=create_sliding_window_subgraphs,\n",
    "    device=device,\n",
    "    k=3,\n",
    "    random_seed=42,\n",
    "    **window_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Baseline Performance**: Standard GAT model on full graphs\n",
    "2. **Sliding Window Approach**: Fixed-size subgraph extraction with overlapping windows\n",
    "3. **Attention-based Selection**: Using GAT attention weights to identify most relevant subgraphs\n",
    "4. **Performance Comparison**: Comparing subgraph-based vs full graph approaches\n",
    "5. **Visualization**: Showing which subgraphs contribute most to final predictions\n",
    "\n",
    "The sliding window approach provides a systematic way to create subgraphs while maintaining consistent sizes, which can be beneficial for batch processing and model stability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}